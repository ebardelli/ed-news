"""
This type stub file was generated by pyright.
"""

from typing import List
from functools import lru_cache

"""Feed parsing and normalization utilities.

This module loads feed sources from planet files, fetches and parses feeds,
and provides helpers to extract DOIs, authors, and abstracts from feed
entries. It also contains logic to persist entries into the project's DB.
"""
logger = ...
def entry_has_content(entry: dict) -> bool:
    """Return True if a feedparser entry/dict has usable content.

    Consider title, link, summary/content as evidence of meaningful content.
    """
    ...

def load_feeds() -> List[tuple]:
    """Load feeds from `planet.json` or fallback to `planet.ini`.

    Returns a list of tuples describing each feed: (key, title, url, publication_id, issn).
    """
    ...

def fetch_feed(session, key, feed_title, url, publication_doi=..., issn=..., timeout=...): # -> dict[str, Any]:
    """Fetch and parse a single feed URL.

    Returns a dict containing feed metadata and a list of parsed entries. The
    function attempts to filter entries to those from the feed's most recent
    publication date when possible.
    """
    ...

def title_suitable_for_crossref_lookup(title: str) -> bool:
    """Return True if a title is likely appropriate for a Crossref title lookup.

    Performs simple heuristics such as minimum length, blacklist checks and
    numeric/DOI detection to decide whether a title should be used for a
    Crossref query.
    """
    ...

@lru_cache(maxsize=1024)
def normalize_doi(doi: str | None, preferred_publication_id: str | None = ...) -> str | None:
    """Normalize and canonicalize a DOI-like string.

    Strips common URI prefixes, trailing punctuation and returns the core DOI
    in lowercase if a DOI pattern is detected. If no DOI is found but the
    input looks like a title, this function may attempt a Crossref lookup.
    """
    ...

def extract_doi_from_entry(entry) -> str | None:
    """Try to extract a DOI from a feed entry.

    The function examines common fields such as 'doi', 'links', 'id', and the
    contents of 'summary' and 'content' looking for DOI patterns or DOI URLs.
    Returns a normalized DOI or None.
    """
    ...

def extract_and_normalize_doi(entry, preferred_publication_id: str | None = ...) -> str | None:
    """Centralized DOI extraction helper.

    Accepts a feedparser entry or a plain dict. Returns a canonicalized DOI
    (lowercase, stripped prefixes/punctuation) or None. If the extracted value
    looks like a title, the function may attempt a Crossref lookup using the
    optional preferred_publication_id.
    """
    ...

def extract_authors_from_entry(entry) -> str | None:
    """Extract a comma-separated author string from a feed entry.

    Supports feedparser-style `authors` lists as well as legacy `author` and
    `dc_creator` fields. Returns a single string or None.
    """
    ...

def extract_abstract_from_entry(entry) -> str | None:
    """Extract an abstract/summary text from a feed entry.

    Prefers `summary` then the first `content` block. HTML tags are stripped
    and entities unescaped.
    """
    ...

def save_entries(conn, feed_id, feed_title, entries):
    """Persist feed entries into the database `items` table.

    Performs deduplication by link and attempts to attach DOIs and upsert
    related article records when a DOI is found.
    """
    ...

