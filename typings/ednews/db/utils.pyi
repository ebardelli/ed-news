"""
This type stub file was generated by pyright.
"""

"""Utility helpers for DB migrations: url hashing and duplicate resolution.

These functions are small, pure where possible, and easy to unit-test.
"""
logger = ...
def compute_url_hash(link: str | None) -> str | None:
    """Compute a deterministic hex SHA-256 hash for a URL string.

    Returns None for falsy links.
    """
    ...

def backfill_missing_url_hash(conn) -> tuple[int, list[str]]:
    """Backfill url_hash for rows in `items` that have a link but missing url_hash.

    Returns (updated_count, collisions)
    where collisions is a list of url_hash values that could not be written due to
    unique-constraint collisions.
    """
    ...

def resolve_url_hash_collisions(conn, url_hashes: list[str | None] | None = ...) -> tuple[int, list[str]]:
    """Resolve duplicate rows that share the same url_hash.

    If `url_hashes` is None, detect all url_hash values that occur more than once.
    For each group, keep the row with the earliest COALESCE(published, fetched_at)
    (ties broken by id), merge doi/published into the kept row when missing, and
    delete the other rows.

    Returns (resolved_count, unresolved_hashes).
    """
    ...

