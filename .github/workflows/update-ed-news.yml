name: update ed-news website

on:
  workflow_dispatch: {}
  schedule:
    # Run hourly from 06:00–18:00 Pacific Time.
    # - PST (UTC-8): 14:00–02:00 UTC -> cron '0 14-23,0-2 * * *'
    - cron: '0 14-23,0-2 * * *'
  push:
    branches: [ main ]

permissions:
  contents: read
  id-token: write
  pages: write

jobs:
  update-site:
    runs-on: ubuntu-latest

    env:
      PYTHON_GIL: 0
      UV_CACHE_DIR: /tmp/.uv-cache

    steps:
      - name: Checkout repository
        uses: actions/checkout@de0fac2e4500dabe0009e67214ff5f5447ce83dd # v6.0.2

      - name: Install the latest version of uv
        uses: astral-sh/setup-uv@eac588ad8def6316056a12d4907a9d4d84ff7a3b # v7.3.0

      - name: Restore uv cache
        uses: actions/cache@cdf6c1fa76f9f475f3d7449005a359c84ca0f306 # v5.0.3
        with:
          path: /tmp/.uv-cache
          key: uv-${{ runner.os }}-${{ hashFiles('uv.lock') }}
          restore-keys: |
            uv-${{ runner.os }}-${{ hashFiles('uv.lock') }}
            uv-${{ runner.os }}

      - name: Find release asset
        id: find_release_asset
        shell: bash
        run: |
          set -e

          echo "::Group::Inputs"
          echo "${{ toJSON(inputs) }}"
          echo "::endgroup::"

          echo "::group::Runner Context"
          echo "${{ toJSON(runner) }}"
          echo "::endgroup::"

          tag="2.3.0"
          version="${tag#v}"
          os="${{ runner.os }}"
          arch="${{ runner.arch || 'X64' }}"
          extension=".tar.gz"

          case "${os}" in
          Linux)
              os="Linux"
              ;;
          macOS)
              os="macOS"
              ;;
          *)
              echo "Unknown OS: ${os}"
              exit 1
              ;;
          esac

          case "${arch}" in
          X32)
              arch="32bit"
              ;;
          X64)
              arch="64bit"
              ;;
          ARM)
              arch="armv6"
              ;;
          ARM64)
              arch="arm64"
              ;;
          *)
              echo "Unknown architecture: ${arch}"
              exit 1
              ;;
          esac

          asset_name="s5cmd_${version}_${os}-${arch}${extension}"
          asset_url="http://trunk.s3-website.ebardelli.com/${asset_name}"

          echo "::group::Asset URL"
          echo "${asset_url}"
          echo "::endgroup::"

          if [ -z "$asset_url" ]; then
            echo "Unable to find asset ${asset_name} for version ${tag}"
            exit 1
          fi

          echo "url=${asset_url}" >> "$GITHUB_OUTPUT"

      - name: Download release asset
        id: download_release
        if: steps.find_release_asset.outputs.url != ''
        shell: bash
        run: |
          set -e

          asset_url="${{ steps.find_release_asset.outputs.url }}"
          tmp_dir="${{ runner.temp }}"

          download_dir="$tmp_dir/s5cmd-asset"
          binary_dir="$tmp_dir/s5cmd-bin"

          mkdir -p "$download_dir"
          mkdir -p "$binary_dir"

          archive_path="${download_dir}/s5cmd.tar.gz"

          curl -sL -o "${archive_path}" "${asset_url}"

          echo "::group::Download archive"
          ls -l "${archive_path}"
          echo "::endgroup::"

          tar -xf "${archive_path}" -C "${binary_dir}" s5cmd

          echo "::group::Binary path"
          ls -l "${binary_dir}"
          echo "::endgroup::"

          echo "binary_dir=${binary_dir}" >> "$GITHUB_OUTPUT"

      - name: Add s5cmd to path
        shell: bash
        run: |
          s5cmd_binary_dir="${{ steps.download_release.outputs.binary_dir  }}"
          echo "${s5cmd_binary_dir}" >> $GITHUB_PATH

      - name: Restore S3 cache
        run: s5cmd --endpoint-url $AWS_ENDPOINT cp s3://ed-news-cache/ednews.db ednews.db
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.GARAGE_ACCESS_KEY }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.GARAGE_SECRET_KEY }}
          AWS_ENDPOINT: ${{ secrets.GARAGE_ENDPOINT }}
          AWS_DEFAULT_REGION: ${{ secrets.GARAGE_DEFAULT_REGION }}

      - name: Install dependencies
        run: uv sync

      - name: Fetch and build website
        run: |
          uv run python main.py fetch

          uv run python main.py issn-lookup --date-filter-type created --from-date '2025-01-01' --per-journal 100
          uv run ednews postprocess
          
          uv run python main.py embed
          uv run python main.py build

      - name: Upload ednews.db to S3 cache
        run: s5cmd --endpoint-url $AWS_ENDPOINT cp ednews.db s3://ed-news-cache/
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.GARAGE_ACCESS_KEY }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.GARAGE_SECRET_KEY }}
          AWS_ENDPOINT: ${{ secrets.GARAGE_ENDPOINT }}
          AWS_DEFAULT_REGION: ${{ secrets.GARAGE_DEFAULT_REGION }}

      - name: Sync build/ to S3
        run: s5cmd --endpoint-url $AWS_ENDPOINT sync --delete build/ s3://ed-news/
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.GARAGE_ACCESS_KEY }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.GARAGE_SECRET_KEY }}
          AWS_ENDPOINT: ${{ secrets.GARAGE_ENDPOINT }}
          AWS_DEFAULT_REGION: ${{ secrets.GARAGE_DEFAULT_REGION }}

      - name: Purge Cloudflare cache
        uses: jakejarvis/cloudflare-purge-action@eee6dba0236093358f25bb1581bd615dc8b3d8e3 # v0.3.0
        env:
          CLOUDFLARE_ZONE: ${{ secrets.CLOUDFLARE_ZONE_IDENTIFIER }}
          CLOUDFLARE_TOKEN: ${{ secrets.CLOUDFLARE_TOKEN }}

      # Deploy build to GitHub Pages
      - name: Setup Pages
        uses: actions/configure-pages@983d7736d9b0ae728b81ab479565c72886d7745b # v5.0.0
      - name: Upload artifact
        uses: actions/upload-pages-artifact@7b1f4a764d45c48632c6b24a0339c27f5614fb0b # v4.0.0
        with:
          path: 'build/'
      - name: Deploy to GitHub Pages
        id: deployment
        uses: actions/deploy-pages@d6db90164ac5ed86f2b6aed7e0febac5b3c0c03e # v4.0.5

      - name: Minimize uv cache
        run: uv cache prune --ci
      
